# TinyML_robustness_analysis

## Models to Analyze (Taken from MLPerf Tiny Benchmark): 
- Visual Wake Words (MobileNetV1)
- Image Classification (ResNet)

## Research Questions:

### Model Extraction:
- How does the search space of model extraction attacks differ between TinyML models and larger MLaaS models? Are model extraction attacks easier in this setting? Do they cost less (# of queries)? (measured in accuracy / fidelity)

### Model Evasion (has not been looked at extensively):
- How transferable are adversarial examples generated by functional equivalent models to the target model? (Measured in efficacy)
- What are the costs of pre-processing based defences (feature squeezing) for TinyML class devices (power, memory)?
 
### Poisoning / Backdoors (has not been looked at):
- What are the effects of a poisoned / backdoored dataset on TinyML models? Does the PTQ process make these attacks more or less effective? (measured in error / success rate)
- Look at full size MobileNetV1 for example with 5% poisoned and PTQ with 5% poisoned, compare, do with different percentages of dataset poisoned

### Model Inversion (has not been looked at):
- Does the size of TinyML models make model inversion attacks easier? Harder? Does the quantization of the weights provide less information, thus making recovering training samples more difficult?
